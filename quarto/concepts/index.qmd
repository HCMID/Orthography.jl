---
title: Concepts
---



An *orthographic system* comprises a specified character set with defined semantics. Since its character set is specified, we can enumerate the valid characters in an orthographic system, and determine whether or not an arbitrary character or codepoint belongs to that set.

The semantics of an orthographic system determine how its characters can be validly combined to form *tokens*. 

A *token* is a string of valid characters

a text using that orthography can be tokenized.


```{julia}
using Orthography
ortho = simpleAscii()
```


- explicitly defines a set of token types
- explicitly defines a character set or set of code points that can compose tokens
- uses semantics of the character set to parse text into sequences of tokens with associated token type


The tokenizing functionality can be applied to strings of text, citable text passages, or entire citable corpora.  It can be applied to index a corpus by token, to compile token lists for a corpus, to compute token histograms for a corpus, and to generate a new corpus citable at the level of the token.


