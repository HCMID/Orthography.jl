---
title: Tokenization
---

Orthographies allow you to break up a continuous passage of text into a series of tokens. The examples on this page use `SimpleAscii`, an orthography for a basic alphabetic subset of the ASCII character set.



```{julia}
using Orthography
orthography = simpleAscii()
s = "Four score and seven years ago..."
tokens = tokenize(s, orthography)
```



Tokenization parses a string value into a sequence of classified substrings.  For substrings that are valid in the orthographic system, the classification will be one of the token types enumerated for that orthographic system.

You can use a tokenizer to tokenize strings, citable passages of texts, or entire text corpora.

## Tokenizing strings

When you tokenize a literal string, the result is a list of `OrthographicToken`s.


tokens[1] |> typeof 


Each `OrthographicToken` has a string value and a classifying category.


tokens[1]

tokens[2]

## Tokenizing citable passage

When you tokenize a `CitablePassage`, the result is a list of `CitablePassage`s paired with token categories.  The text value of each node is the token, and the URN value is cited with one level of citation beyond the original passage so that each token node is uniquely identified.


using CitableText, CitableCorpus
urn = CtsUrn("urn:cts:orthodocs:tokenization.docs.v1:stooges")
cn = CitablePassage(urn, s)
tokenizednodes = tokenize(cn, orthography)
tokenizednodes[1]



tokenizednodes[2]




### Specifying resulting URNs

When you are tokenizing citable content (either `CitablePassage`s or a `CitableTextCorpus`), you can include optional parameters to specify the form of the citable tokenized content:

- `edition` will be used as the value of the version identifier
- `exemplar` will be used as the value of the exemplar identifier

You may include either or neither.  If neither is specified, the resulting URNs are cited at the version level with a version identifier composed of the source version identifer concatenated with `_tokens`.

labellededition = tokenize(cn, orthography, edition = "special_edition_id")
labellededition[1]


labelledexemplars = tokenize(cn, orthography, exemplar = "tokens")
labelledexemplars[1]



## Tokenizing a citable text corpus

If you tokenize a `CitableTextCorpus`, you get the same kind of pairing of citable nodes with token categories as when you parse a `CitablePassage`.  If your text corpus has only a single node, the results will therefore be equal to parsing that node separately, as this example shows.

corpus = CitableTextCorpus([cn])
tokenizedcorpus = tokenize(corpus, orthography)
tokenizedcorpus == tokenizednodes


## Types of tokens


The `tokentypes` function tells you what kinds of token a given orthography recognizes.
```{julia}
using Orthography
orthography = simpleAscii()
tokentypes(orthography)
```

