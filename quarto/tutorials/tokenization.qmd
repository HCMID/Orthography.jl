---
title: Tokenization
---


Orthographies allow you to break up a continuous passage of text into a series of tokens. The examples on this page use `SimpleAscii`, an orthography for a basic alphabetic subset of the ASCII character set.



```{julia}
#| output: false
using Orthography
orthography = simpleAscii()
```

Tokenization parses a string value into a sequence of classified substrings.  For substrings that are valid in the orthographic system, the classification will be one of the token types enumerated for that orthographic system.

```{julia}
tokentypes(orthography)
```

## Tokenizing strings

To use the `tokenize` function, supply a string value and an orthography.

```{julia}
s = "Four score and seven years ago..."
tokens = tokenize(s, orthography)
```

The result is a vector of `OrthographicToken`s. You can find the text content of a token with the `tokentext` function.

```{julia}
tokens[1] |> tokentext
```



The `tokencategory` function tells you the type of a token.

```{julia}
tokens .|> tokencategory
```

A common pattern is to filter a token to include only tokens of a particular type,  e.g., lexical tokens for a morphological or lexical analysis.

```{julia}
lextokens = filter(t -> tokencategory(t) isa LexicalToken, tokens)
```

You could then use Julia broadcasting to extract the text value of all the lexical tokens.

```{julia}
vocab = lextokens .|> tokentext
```

## Tokenizing citable texts

The `tokenize` function is also aware of the structures of citable texts defined in the `CitableText` package. In addition to tokenizing string values, you can tokenize a `CitablePassage` or a `CitableTextCorpus`.


### Citable passages





When you tokenize a `CitablePassage`, the result is a list of `CitablePassage`s paired with token categories.  The text value of each node is the token, and the URN value is cited with one level of citation beyond the original passage so that each token node is uniquely identified.

```{julia}
using CitableText, CitableCorpus
urn = CtsUrn("urn:cts:orthodocs:tokenization.docs.v1:sample")
cn = CitablePassage(urn, s)
tokenizednodes = tokenize(cn, orthography)
tokenizednodes[1]
```


tokenizednodes[2]




### Specifying resulting URNs

When you are tokenizing citable content (either `CitablePassage`s or a `CitableTextCorpus`), you can include optional parameters to specify the form of the citable tokenized content:

- `edition` will be used as the value of the version identifier
- `exemplar` will be used as the value of the exemplar identifier

You may include either or neither.  If neither is specified, the resulting URNs are cited at the version level with a version identifier composed of the source version identifer concatenated with `_tokens`.

labellededition = tokenize(cn, orthography, edition = "special_edition_id")
labellededition[1]


labelledexemplars = tokenize(cn, orthography, exemplar = "tokens")
labelledexemplars[1]



## Tokenizing a citable text corpus

If you tokenize a `CitableTextCorpus`, you get the same kind of pairing of citable nodes with token categories as when you parse a `CitablePassage`.  If your text corpus has only a single node, the results will therefore be equal to parsing that node separately, as this example shows.

corpus = CitableTextCorpus([cn])
tokenizedcorpus = tokenize(corpus, orthography)
tokenizedcorpus == tokenizednodes
